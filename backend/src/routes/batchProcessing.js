import express from 'express';
import multer from 'multer';
import { v4 as uuidv4 } from 'uuid';
import DocumentParser from '../services/documentParser.js';

const router = express.Router();
const documentParser = new DocumentParser();

// Configure multer for file uploads
const upload = multer({
  storage: multer.memoryStorage(),
  limits: {
    fileSize: 10 * 1024 * 1024, // 10MB per file
    files: 20 // Max 20 files per request
  },
  fileFilter: (req, file, cb) => {
    // Accept PDF and image files
    const allowedTypes = ['application/pdf', 'image/png', 'image/jpeg', 'image/jpg'];
    if (allowedTypes.includes(file.mimetype)) {
      cb(null, true);
    } else {
      cb(new Error(`File type ${file.mimetype} not allowed. Accepted: ${allowedTypes.join(', ')}`), false);
    }
  }
});

/**
 * POST /api/batch-processing/initialize
 * Initialize a new batch processing session
 */
router.post('/initialize', async (req, res) => {
  try {
    const { userId, fileCount, totalSize } = req.body;

    console.log(`üì¶ Initializing batch for user ${userId}: ${fileCount} files, ${Math.round(totalSize / 1024)}KB`);

    // Create batch record in database
    const batchId = uuidv4();
    
    try {
      await req.db.query(`
        INSERT INTO batch_processing (
          batch_id, user_id, total_files, status, created_at
        ) VALUES ($1, $2, $3, $4, $5)
      `, [batchId, userId, fileCount, 'initialized', new Date().toISOString()]);
    } catch (dbError) {
      console.log('Database table may not exist yet, proceeding with batch ID');
    }

    res.json({
      success: true,
      batchId,
      status: 'initialized',
      totalFiles: fileCount,
      estimatedTime: fileCount * 3 // 3 seconds per file estimate
    });

  } catch (error) {
    console.error('‚ùå Failed to initialize batch:', error);
    res.status(500).json({
      error: 'Batch initialization failed',
      message: error.message
    });
  }
});

// Store uploaded files temporarily for processing
const batchFiles = new Map();

/**
 * POST /api/batch-processing/upload
 * Upload files and start batch processing
 */
router.post('/upload', upload.array('files', 20), async (req, res) => {
  try {
    const { batchId, userId } = req.body;
    const files = req.files;

    if (!files || files.length === 0) {
      return res.status(400).json({
        error: 'No files uploaded',
        message: 'Please select files to upload'
      });
    }

    if (!batchId) {
      return res.status(400).json({
        error: 'Batch ID required',
        message: 'Please initialize batch before uploading'
      });
    }

    console.log(`üì§ Starting batch upload: ${files.length} files for batch ${batchId}`);
    console.log('üìã Files received:', files.map(f => `${f.originalname} (${f.size} bytes, ${f.mimetype})`));

    // Store files in memory for processing
    batchFiles.set(batchId, files);

    // Update batch status
    try {
      await req.db.query(`
        UPDATE batch_processing 
        SET status = 'uploading', total_files = $1, updated_at = $2
        WHERE batch_id = $3
      `, [files.length, new Date().toISOString(), batchId]);
    } catch (dbError) {
      console.log('Database update failed, continuing with processing');
    }

    res.json({
      success: true,
      batchId,
      uploadedFiles: files.length,
      totalSize: files.reduce((sum, f) => sum + f.size, 0),
      status: 'uploaded',
      nextStep: 'processing'
    });

  } catch (error) {
    console.error('‚ùå Batch upload failed:', error);
    
    // Update batch status to failed
    if (req.body.batchId) {
      try {
        await req.db.query(`
          UPDATE batch_processing 
          SET status = 'failed', error_details = $1, updated_at = $2
          WHERE batch_id = $3
        `, [JSON.stringify({ error: error.message }), new Date().toISOString(), req.body.batchId]);
      } catch (dbError) {
        console.error('Failed to update batch status:', dbError);
      }
    }

    res.status(500).json({
      error: 'Upload failed',
      message: error.message,
      batchId: req.body.batchId
    });
  }
});

/**
 * POST /api/batch-processing/process/:batchId
 * Start OCR processing for a batch
 */
router.post('/process/:batchId', async (req, res) => {
  try {
    const { batchId } = req.params;

    console.log(`üîÑ Starting OCR processing for batch ${batchId}`);

    // Update batch status
    try {
      await req.db.query(`
        UPDATE batch_processing 
        SET status = 'processing', updated_at = $1
        WHERE batch_id = $2
      `, [new Date().toISOString(), batchId]);
    } catch (dbError) {
      console.log('Database update failed, continuing with processing');
    }

    // Get uploaded files for this batch
    const files = batchFiles.get(batchId);
    if (!files || files.length === 0) {
      throw new Error(`No files found for batch ${batchId}. Please upload files first.`);
    }

    console.log(`üîÑ Processing ${files.length} files for batch ${batchId}`);

    // Process each file with DocumentParser
    const extractedShipments = [];
    const errors = [];
    
    for (let i = 0; i < files.length; i++) {
      const file = files[i];
      try {
        console.log(`üîç Processing file ${i + 1}/${files.length}: ${file.originalname}`);
        
        // Parse document using OCR service
        const parseResult = await documentParser.parseDocument(
          file.buffer,
          file.mimetype,
          file.originalname
        );
        
        // Extract shipment data from parsed document
        const shipmentData = {
          shipment_id: uuidv4(),
          source_file: file.originalname,
          document_type: parseResult.documentType,
          confidence_score: parseResult.confidence / 100, // Convert to decimal
          export_date: parseResult.extractedFields.target_export_date || '2024-12-01',
          mode: parseResult.extractedFields.transport_mode || 'air',
          destination_country: parseResult.extractedFields.destination_country || 'Unknown',
          end_user_name: parseResult.extractedFields.consignee_name || parseResult.extractedFields.end_user_consignee_name || 'Unknown',
          commercial_value: parseFloat(parseResult.extractedFields.commercial_value) || 0,
          currency: parseResult.extractedFields.currency || 'USD',
          incoterms: parseResult.extractedFields.incoterms || 'FOB',
          hs_code: parseResult.extractedFields.hs_code || '',
          quantity: parseFloat(parseResult.extractedFields.quantity) || 0,
          product_description: parseResult.extractedFields.product_description || '',
          technology_origin: parseResult.extractedFields.technology_origin || ''
        };
        
        extractedShipments.push(shipmentData);
        console.log(`‚úÖ Successfully processed: ${file.originalname} as ${parseResult.documentType}`);
        
      } catch (error) {
        console.error(`‚ùå Error processing ${file.originalname}:`, error.message);
        errors.push({
          filename: file.originalname,
          error: error.message
        });
      }
    }

    const processingResults = {
      batchId,
      processedFiles: extractedShipments.length,
      failedFiles: errors.length,
      extractedShipments,
      errors: errors.length > 0 ? errors : undefined
    };

    // Clean up stored files after processing
    batchFiles.delete(batchId);

    // Update batch with results
    try {
      await req.db.query(`
        UPDATE batch_processing 
        SET status = $1, processed_files = $2, failed_files = $3, 
            extracted_shipments = $4, updated_at = $5
        WHERE batch_id = $6
      `, [
        'completed',
        processingResults.processedFiles,
        processingResults.failedFiles,
        processingResults.extractedShipments.length,
        new Date().toISOString(),
        batchId
      ]);
    } catch (dbError) {
      console.log('Database update failed');
    }

    res.json({
      success: true,
      batchId,
      ...processingResults
    });

  } catch (error) {
    console.error(`‚ùå OCR processing failed for batch ${req.params.batchId}:`, error);
    
    // Update batch status to failed
    try {
      await req.db.query(`
        UPDATE batch_processing 
        SET status = 'failed', error_details = $1, updated_at = $2
        WHERE batch_id = $3
      `, [JSON.stringify({ error: error.message }), new Date().toISOString(), req.params.batchId]);
    } catch (dbError) {
      console.error('Failed to update batch status:', dbError);
    }

    res.status(500).json({
      error: 'OCR processing failed',
      message: error.message,
      batchId: req.params.batchId
    });
  }
});

/**
 * POST /api/batch-processing/save/:batchId
 * Save extracted data to database
 */
router.post('/save/:batchId', async (req, res) => {
  try {
    const { batchId } = req.params;

    console.log(`üíæ Saving batch ${batchId} to database`);

    // TODO: Implement actual database save logic
    const saveResults = {
      success: true,
      batchId,
      savedShipments: [{
        shipment_id: uuidv4(),
        source_file: 'sample_invoice.pdf',
        product_count: 1,
        total_value: 15000
      }],
      totalValue: 15000,
      nextStep: {
        step: 4,
        stepName: 'General Screening',
        reason: 'Standard products - skip specialized screenings',
        priority: 'normal'
      }
    };

    // Update batch completion
    try {
      await req.db.query(`
        UPDATE batch_processing 
        SET status = 'saved', completed_at = $1, updated_at = $1,
            total_value = $2
        WHERE batch_id = $3
      `, [
        new Date().toISOString(),
        saveResults.totalValue,
        batchId
      ]);
    } catch (dbError) {
      console.log('Database update failed');
    }

    res.json({
      success: true,
      batchId,
      ...saveResults
    });

  } catch (error) {
    console.error(`‚ùå Failed to save batch ${req.params.batchId}:`, error);
    
    // Update batch status to failed
    try {
      await req.db.query(`
        UPDATE batch_processing 
        SET status = 'save_failed', error_details = $1, updated_at = $2
        WHERE batch_id = $3
      `, [JSON.stringify({ error: error.message }), new Date().toISOString(), req.params.batchId]);
    } catch (dbError) {
      console.error('Failed to update batch status:', dbError);
    }

    res.status(500).json({
      error: 'Database save failed',
      message: error.message,
      batchId: req.params.batchId
    });
  }
});

/**
 * GET /api/batch-processing/status/:batchId
 * Get batch processing status
 */
router.get('/status/:batchId', async (req, res) => {
  try {
    const { batchId } = req.params;

    // Try to get from database first
    try {
      const dbResult = await req.db.query(`
        SELECT * FROM batch_processing WHERE batch_id = $1
      `, [batchId]);

      if (dbResult.rows.length > 0) {
        const dbBatch = dbResult.rows[0];
        return res.json({
          success: true,
          batchId,
          status: dbBatch.status,
          totalFiles: dbBatch.total_files,
          processedFiles: dbBatch.processed_files,
          failedFiles: dbBatch.failed_files,
          extractedShipments: dbBatch.extracted_shipments,
          totalValue: dbBatch.total_value,
          startTime: dbBatch.started_at,
          endTime: dbBatch.completed_at,
          errorDetails: dbBatch.error_details
        });
      }
    } catch (dbError) {
      console.log('Database query failed, returning default status');
    }

    // Default response if database is not available
    res.json({
      success: true,
      batchId,
      status: 'unknown',
      message: 'Batch status not found'
    });

  } catch (error) {
    console.error(`‚ùå Failed to get batch status for ${req.params.batchId}:`, error);
    res.status(500).json({
      error: 'Failed to retrieve batch status',
      message: error.message,
      batchId: req.params.batchId
    });
  }
});

/**
 * GET /api/batch-processing/batches/recent
 * Get recent batch processing sessions
 */
router.get('/batches/recent', async (req, res) => {
  try {
    const limit = parseInt(req.query.limit) || 20;
    const userId = req.query.userId;

    try {
      let query = `
        SELECT 
          bp.*,
          COUNT(s.shipment_id) as created_shipments
        FROM batch_processing bp
        LEFT JOIN shipments s ON bp.batch_id = s.batch_id
      `;
      
      const params = [limit];
      
      if (userId) {
        query += ` WHERE bp.user_id = $${params.length + 1}`;
        params.push(userId);
      }
      
      query += `
        GROUP BY bp.batch_id
        ORDER BY bp.created_at DESC
        LIMIT $1
      `;

      const result = await req.db.query(query, params);

      res.json({
        success: true,
        batches: result.rows,
        count: result.rows.length,
        limit
      });
    } catch (dbError) {
      console.log('Database query failed, returning empty array');
      res.json({
        success: true,
        batches: [],
        count: 0,
        limit
      });
    }

  } catch (error) {
    console.error('‚ùå Failed to get recent batches:', error);
    res.status(500).json({
      error: 'Failed to retrieve recent batches',
      message: error.message
    });
  }
});

export { router as batchProcessingRouter };
